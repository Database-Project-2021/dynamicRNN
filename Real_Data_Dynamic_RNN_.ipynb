{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic RNN Make Pratical\n",
    "\n",
    "Modify from this [notebook](https://www.kaggle.com/winternguyen/predict-household-electric-power-using-lstms)\n",
    "\n",
    "Download the dataset from this [link](https://www.kaggle.com/uciml/electric-power-consumption-data-set) and put this dataset under the `dataset` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.050066,
     "end_time": "2021-05-22T14:20:47.676992",
     "exception": false,
     "start_time": "2021-05-22T14:20:47.626926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/household_power_consumption.txt\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-test.zip\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-train.zip\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/transaction-cpu-time-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/transaction-dependencies.txt\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/transaction-diskio-count-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/transaction-features.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/transaction-latency-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/transaction-networkin-size-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/transaction-networkout-size-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/description\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/HEAD\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/config\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/FETCH_HEAD\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/index\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/COMMIT_EDITMSG\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/applypatch-msg.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/commit-msg.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/post-update.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/pre-applypatch.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/pre-commit.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/pre-push.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/pre-rebase.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/prepare-commit-msg.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/update.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/fsmonitor-watchman.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/pre-merge-commit.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/pre-receive.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/hooks/push-to-checkout.sample\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/info/exclude\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/refs/heads/master\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/03/cdd52b3619e931d31b34fdcd0b6872fe07fc2a\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/d7/3b2ad9539c3f1a05bf246f915d3641524c46cd\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/de/8f537acff666f5fae4f97544363741ea5c4977\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/33/96ee89a380e42895330f25a70ed06f2ce1a013\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/66/22cfe072ede1c8e65318380028f6fa3b028daf\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/73/0cf467f371830955e48627513349080899ba9b\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/f2/b9b071b3a380c80cb5b70c2da99112374eae7c\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/98/ac22fc900b806e11d05b6262deead18cba6648\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/objects/2a/01aab0063b71ed438db0e44e88d2c674f6d405\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/logs/HEAD\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx-testing-data/training-data/.git/logs/refs/heads/master\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-cpu-time-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-dependencies.txt\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-diskio-count-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-features.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-latency-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-networkin-size-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-networkout-size-server-0.csv\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-features.pkl\n",
      "dataset/mmt-rte-45-server-1-no-dist-tx/training-data/latency.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from IPython.display import display\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('dataset'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028972,
     "end_time": "2021-05-22T14:20:47.735666",
     "exception": false,
     "start_time": "2021-05-22T14:20:47.706694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import & cleaning data\n",
    "\n",
    "Importing the txt file takes more time than that of csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cost_estimator import Loader, Preprocessor, RegressionModels, Task\n",
    "\n",
    "def get_df(dataset_path: Union[str, list]):\n",
    "    ou_name = 'OU2 - Initialize Thread'\n",
    "    task_name = 'latency'\n",
    "    features = ['System CPU Load', 'Process CPU Load',\n",
    "                'System Load Average', 'Thread Active Count']\n",
    "    sample_size = 10000\n",
    "\n",
    "    task = Task(ou_name, task_name)\n",
    "    if isinstance(dataset_path, str):\n",
    "        dataset_path = [dataset_path]\n",
    "        \n",
    "    df_list = []\n",
    "\n",
    "    for path in dataset_path:\n",
    "        # sub_task_name = f'basic1-RTE-{i}'\n",
    "\n",
    "        loader = Loader(path, server_count=1, n_jobs=8)\n",
    "        df_features = loader.load_features_as_df(load_from_pkl=True)\n",
    "        df_latencies = loader.load_latencies_as_df(load_from_pkl=True)\n",
    "        dict_depend = loader.load_dependencies_as_dict()\n",
    "        \n",
    "        df_list.append((df_features, df_latencies, dict_depend))\n",
    "\n",
    "        # print(f'\\n\\n---------------------- Basic1-RTE-{i} Latency ----------------------')\n",
    "        psr = Preprocessor(df_features, df_latencies, ou_name)\n",
    "        psr.drop_warmup_data()\n",
    "\n",
    "        mean_before_filter = float(psr.get_label().mean())\n",
    "        std_before_filter = float(psr.get_label().std())\n",
    "\n",
    "        psr.drop_outlier_and_na(drop_alg='std')\n",
    "\n",
    "        mean_after_filter = float(psr.get_label().mean())\n",
    "        std_after_filter = float(psr.get_label().std())\n",
    "\n",
    "        psr.sample_features(sample_size)\n",
    "        psr.specify_features(features)\n",
    "        \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load features from dataset/mmt-rte-45-server-1-no-dist-tx/training-data/transaction-features.pkl\n",
      "Load label from dataset/mmt-rte-45-server-1-no-dist-tx/training-data/latency.pkl\n",
      "Drop warmup size: 81808, Size before/after drop warmup data: 265500/183692\n",
      "Drop na size: 0, Size before/after drop na data: 183692/183692\n",
      "Drop outlier size: 23699, Size before/after drop outlier data: 183692/159993\n",
      "Drop sample size: 159993, Size before/after sample: 159993/10000\n",
      "current feature columns: ['System CPU Load', 'Process CPU Load', 'System Load Average', 'Thread Active Count']\n"
     ]
    }
   ],
   "source": [
    "df_list = get_df(dataset_path=['dataset/mmt-rte-45-server-1-no-dist-tx/training-data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_NaN(df):\n",
    "    df.isnull().sum()\n",
    "    df = df.fillna(df.mean())\n",
    "    df.isnull().sum()\n",
    "    # return df\n",
    "\n",
    "def make_dataset(df_features, df_latencies, dict_depend):\n",
    "    df_start_time = df_features[['Transaction ID', 'Start Time']]\n",
    "    df_total_time = df_latencies[['Total']]\n",
    "    df_feature = df_latencies[['Is Distributed', 'Total', 'OU0 - Broadcast', 'OU0 - ROUTE', 'OU1 - Generate Plan', 'OU2 - Initialize Thread',\n",
    "                               'OU3 - Acquire Locks', 'OU4 - Read from Local', 'OU5M - Read from Remote', 'OU6 - Execute Arithmetic Logic', \n",
    "                               'NonOU - Push to Remote', 'OU7 - Write to Local', 'OU8 - Commit']]\n",
    "    \n",
    "    max_depend_num = 0\n",
    "    depends = []\n",
    "    \n",
    "    for k in dict_depend.keys():\n",
    "        depend_num = len(dict_depend[k])\n",
    "        if max_depend_num < depend_num:\n",
    "            max_depend_num = depend_num\n",
    "        \n",
    "    for index, row in df_features.iterrows():\n",
    "        # print(f\"ID: {row['Transaction ID']} | Start: {row['Start Time']} | Total: {row['Total']}\") \n",
    "        if dict_depend is not None:\n",
    "            depend_txns = dict_depend.get(row['Transaction ID'], None)\n",
    "            \n",
    "#             If no dependent Txns, assign a empty list\n",
    "            if depend_txns is None:\n",
    "                depend_txns = []\n",
    "            else:\n",
    "                for i in range(len(depend_txns)):\n",
    "                    depend_txns[i] = row['Transaction ID'] - depend_txns[i]\n",
    "                \n",
    "            depend_txns_num = len(depend_txns)\n",
    "\n",
    "            if depend_txns_num <= max_depend_num:\n",
    "                depends.append(depend_txns + ([0] * (max_depend_num - depend_txns_num)))\n",
    "            else:\n",
    "#                 If exceed the maximum number of dependenet Txns, truncate\n",
    "                depends.append(depend_txns[:max_depend_num])\n",
    "    \n",
    "    df_depends = pd.DataFrame(depends, columns=[f\"dep-{i}\" for i in range(1, max_depend_num + 1)], dtype=np.int64)\n",
    "    df_concat = pd.concat([df_start_time, df_feature, df_depends], axis=1)\n",
    "    df_concat['Is Distributed'] = df_concat['Is Distributed'].astype(int)\n",
    "    \n",
    "    # df_X = df_concat.drop(columns=['OU3 - Acquire Locks'])\n",
    "    df_X = df_concat\n",
    "    df_Y = pd.DataFrame(df_features['Start Time'] + df_total_time['Total'], columns=['End Time'])\n",
    "    \n",
    "    return df_X, df_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_X shape: (265500, 72)\n",
      "df_train_Y shape: (265500, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Is Distributed</th>\n",
       "      <th>Total</th>\n",
       "      <th>OU0 - Broadcast</th>\n",
       "      <th>OU0 - ROUTE</th>\n",
       "      <th>OU1 - Generate Plan</th>\n",
       "      <th>OU2 - Initialize Thread</th>\n",
       "      <th>OU3 - Acquire Locks</th>\n",
       "      <th>OU4 - Read from Local</th>\n",
       "      <th>...</th>\n",
       "      <th>dep-48</th>\n",
       "      <th>dep-49</th>\n",
       "      <th>dep-50</th>\n",
       "      <th>dep-51</th>\n",
       "      <th>dep-52</th>\n",
       "      <th>dep-53</th>\n",
       "      <th>dep-54</th>\n",
       "      <th>dep-55</th>\n",
       "      <th>dep-56</th>\n",
       "      <th>dep-57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>422772</td>\n",
       "      <td>27650</td>\n",
       "      <td>8166</td>\n",
       "      <td>3002</td>\n",
       "      <td>509</td>\n",
       "      <td>180</td>\n",
       "      <td>331502</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>268962</td>\n",
       "      <td>84840</td>\n",
       "      <td>48902</td>\n",
       "      <td>134</td>\n",
       "      <td>328</td>\n",
       "      <td>18</td>\n",
       "      <td>202749</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>378067</td>\n",
       "      <td>85504</td>\n",
       "      <td>43993</td>\n",
       "      <td>356</td>\n",
       "      <td>1247</td>\n",
       "      <td>91</td>\n",
       "      <td>267447</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>408310</td>\n",
       "      <td>86214</td>\n",
       "      <td>46013</td>\n",
       "      <td>343</td>\n",
       "      <td>319</td>\n",
       "      <td>83</td>\n",
       "      <td>278215</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>257324</td>\n",
       "      <td>86674</td>\n",
       "      <td>46520</td>\n",
       "      <td>87</td>\n",
       "      <td>1446</td>\n",
       "      <td>17</td>\n",
       "      <td>183418</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265495</th>\n",
       "      <td>265496</td>\n",
       "      <td>179945291</td>\n",
       "      <td>0</td>\n",
       "      <td>6535</td>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>4133</td>\n",
       "      <td>1926</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265496</th>\n",
       "      <td>265497</td>\n",
       "      <td>179945293</td>\n",
       "      <td>0</td>\n",
       "      <td>9207</td>\n",
       "      <td>126</td>\n",
       "      <td>234</td>\n",
       "      <td>32</td>\n",
       "      <td>551</td>\n",
       "      <td>4440</td>\n",
       "      <td>1582</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265497</th>\n",
       "      <td>265498</td>\n",
       "      <td>179946896</td>\n",
       "      <td>0</td>\n",
       "      <td>6374</td>\n",
       "      <td>68</td>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>5820</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265498</th>\n",
       "      <td>265499</td>\n",
       "      <td>179946967</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>7</td>\n",
       "      <td>282</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265499</th>\n",
       "      <td>265500</td>\n",
       "      <td>179949938</td>\n",
       "      <td>0</td>\n",
       "      <td>1383</td>\n",
       "      <td>62</td>\n",
       "      <td>817</td>\n",
       "      <td>16</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265500 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Transaction ID  Start Time  Is Distributed   Total  OU0 - Broadcast  \\\n",
       "0                    1           0               0  422772            27650   \n",
       "1                    2          84               0  268962            84840   \n",
       "2                    3          95               0  378067            85504   \n",
       "3                    4         102               0  408310            86214   \n",
       "4                    5         108               0  257324            86674   \n",
       "...                ...         ...             ...     ...              ...   \n",
       "265495          265496   179945291               0    6535               84   \n",
       "265496          265497   179945293               0    9207              126   \n",
       "265497          265498   179946896               0    6374               68   \n",
       "265498          265499   179946967               0     894               82   \n",
       "265499          265500   179949938               0    1383               62   \n",
       "\n",
       "        OU0 - ROUTE  OU1 - Generate Plan  OU2 - Initialize Thread  \\\n",
       "0              8166                 3002                      509   \n",
       "1             48902                  134                      328   \n",
       "2             43993                  356                     1247   \n",
       "3             46013                  343                      319   \n",
       "4             46520                   87                     1446   \n",
       "...             ...                  ...                      ...   \n",
       "265495           71                    9                     4133   \n",
       "265496          234                   32                      551   \n",
       "265497           63                   16                       11   \n",
       "265498          111                    7                      282   \n",
       "265499          817                   16                       96   \n",
       "\n",
       "        OU3 - Acquire Locks  OU4 - Read from Local  ...  dep-48  dep-49  \\\n",
       "0                       180                 331502  ...       0       0   \n",
       "1                        18                 202749  ...       0       0   \n",
       "2                        91                 267447  ...       0       0   \n",
       "3                        83                 278215  ...       0       0   \n",
       "4                        17                 183418  ...       0       0   \n",
       "...                     ...                    ...  ...     ...     ...   \n",
       "265495                 1926                    107  ...       0       0   \n",
       "265496                 4440                   1582  ...       0       0   \n",
       "265497                 5820                    117  ...       0       0   \n",
       "265498                    2                    135  ...       0       0   \n",
       "265499                    2                    114  ...       0       0   \n",
       "\n",
       "        dep-50  dep-51  dep-52  dep-53  dep-54  dep-55  dep-56  dep-57  \n",
       "0            0       0       0       0       0       0       0       0  \n",
       "1            0       0       0       0       0       0       0       0  \n",
       "2            0       0       0       0       0       0       0       0  \n",
       "3            0       0       0       0       0       0       0       0  \n",
       "4            0       0       0       0       0       0       0       0  \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "265495       0       0       0       0       0       0       0       0  \n",
       "265496       0       0       0       0       0       0       0       0  \n",
       "265497       0       0       0       0       0       0       0       0  \n",
       "265498       0       0       0       0       0       0       0       0  \n",
       "265499       0       0       0       0       0       0       0       0  \n",
       "\n",
       "[265500 rows x 72 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>378162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265495</th>\n",
       "      <td>179951826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265496</th>\n",
       "      <td>179954500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265497</th>\n",
       "      <td>179953270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265498</th>\n",
       "      <td>179947861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265499</th>\n",
       "      <td>179951321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         End Time\n",
       "0          422772\n",
       "1          269046\n",
       "2          378162\n",
       "3          408412\n",
       "4          257432\n",
       "...           ...\n",
       "265495  179951826\n",
       "265496  179954500\n",
       "265497  179953270\n",
       "265498  179947861\n",
       "265499  179951321\n",
       "\n",
       "[265500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_X, df_train_Y = make_dataset(df_features=df_list[0][0], df_latencies=df_list[0][1], dict_depend=df_list[0][2])\n",
    "\n",
    "print(f\"df_train_X shape: {df_train_X.shape}\")\n",
    "print(f\"df_train_Y shape: {df_train_Y.shape}\")\n",
    "display(df_train_X)\n",
    "display(df_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUs features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>OU0 - Broadcast</th>\n",
       "      <th>OU0 - ROUTE</th>\n",
       "      <th>OU1 - Generate Plan</th>\n",
       "      <th>OU2 - Initialize Thread</th>\n",
       "      <th>OU3 - Acquire Locks</th>\n",
       "      <th>OU4 - Read from Local</th>\n",
       "      <th>OU5M - Read from Remote</th>\n",
       "      <th>OU6 - Execute Arithmetic Logic</th>\n",
       "      <th>NonOU - Push to Remote</th>\n",
       "      <th>OU7 - Write to Local</th>\n",
       "      <th>OU8 - Commit</th>\n",
       "      <th>dep-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27650</td>\n",
       "      <td>8166</td>\n",
       "      <td>3002</td>\n",
       "      <td>509</td>\n",
       "      <td>180</td>\n",
       "      <td>331502</td>\n",
       "      <td>9</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>69542</td>\n",
       "      <td>5811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>84840</td>\n",
       "      <td>48902</td>\n",
       "      <td>134</td>\n",
       "      <td>328</td>\n",
       "      <td>18</td>\n",
       "      <td>202749</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>16381</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95</td>\n",
       "      <td>85504</td>\n",
       "      <td>43993</td>\n",
       "      <td>356</td>\n",
       "      <td>1247</td>\n",
       "      <td>91</td>\n",
       "      <td>267447</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>64023</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>86214</td>\n",
       "      <td>46013</td>\n",
       "      <td>343</td>\n",
       "      <td>319</td>\n",
       "      <td>83</td>\n",
       "      <td>278215</td>\n",
       "      <td>8</td>\n",
       "      <td>176</td>\n",
       "      <td>2</td>\n",
       "      <td>78655</td>\n",
       "      <td>2907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>86674</td>\n",
       "      <td>46520</td>\n",
       "      <td>87</td>\n",
       "      <td>1446</td>\n",
       "      <td>17</td>\n",
       "      <td>183418</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>25364</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265495</th>\n",
       "      <td>179945291</td>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>4133</td>\n",
       "      <td>1926</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>4</td>\n",
       "      <td>118835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265496</th>\n",
       "      <td>179945293</td>\n",
       "      <td>126</td>\n",
       "      <td>234</td>\n",
       "      <td>32</td>\n",
       "      <td>551</td>\n",
       "      <td>4440</td>\n",
       "      <td>1582</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2280</td>\n",
       "      <td>22</td>\n",
       "      <td>86849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265497</th>\n",
       "      <td>179946896</td>\n",
       "      <td>68</td>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>5820</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>5</td>\n",
       "      <td>45343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265498</th>\n",
       "      <td>179946967</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>7</td>\n",
       "      <td>282</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>5</td>\n",
       "      <td>91614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265499</th>\n",
       "      <td>179949938</td>\n",
       "      <td>62</td>\n",
       "      <td>817</td>\n",
       "      <td>16</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>4</td>\n",
       "      <td>4408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Start Time  OU0 - Broadcast  OU0 - ROUTE  OU1 - Generate Plan  \\\n",
       "0                0            27650         8166                 3002   \n",
       "1               84            84840        48902                  134   \n",
       "2               95            85504        43993                  356   \n",
       "3              102            86214        46013                  343   \n",
       "4              108            86674        46520                   87   \n",
       "...            ...              ...          ...                  ...   \n",
       "265495   179945291               84           71                    9   \n",
       "265496   179945293              126          234                   32   \n",
       "265497   179946896               68           63                   16   \n",
       "265498   179946967               82          111                    7   \n",
       "265499   179949938               62          817                   16   \n",
       "\n",
       "        OU2 - Initialize Thread  OU3 - Acquire Locks  OU4 - Read from Local  \\\n",
       "0                           509                  180                 331502   \n",
       "1                           328                   18                 202749   \n",
       "2                          1247                   91                 267447   \n",
       "3                           319                   83                 278215   \n",
       "4                          1446                   17                 183418   \n",
       "...                         ...                  ...                    ...   \n",
       "265495                     4133                 1926                    107   \n",
       "265496                      551                 4440                   1582   \n",
       "265497                       11                 5820                    117   \n",
       "265498                      282                    2                    135   \n",
       "265499                       96                    2                    114   \n",
       "\n",
       "        OU5M - Read from Remote  OU6 - Execute Arithmetic Logic  \\\n",
       "0                             9                             177   \n",
       "1                             6                              57   \n",
       "2                             9                             200   \n",
       "3                             8                             176   \n",
       "4                             5                              56   \n",
       "...                         ...                             ...   \n",
       "265495                        0                               5   \n",
       "265496                        2                              23   \n",
       "265497                        1                               6   \n",
       "265498                        1                               9   \n",
       "265499                        1                               5   \n",
       "\n",
       "        NonOU - Push to Remote  OU7 - Write to Local  OU8 - Commit   dep-1  \n",
       "0                            2                 69542          5811       0  \n",
       "1                            3                 16381            41       0  \n",
       "2                            2                 64023            87       0  \n",
       "3                            2                 78655          2907       0  \n",
       "4                            3                 25364            43       0  \n",
       "...                        ...                   ...           ...     ...  \n",
       "265495                       0                   232             4  118835  \n",
       "265496                       0                  2280            22   86849  \n",
       "265497                       0                   295             5   45343  \n",
       "265498                       0                   315             5   91614  \n",
       "265499                       0                   293             4    4408  \n",
       "\n",
       "[265500 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"OUs features\")\n",
    "display(df_train_X.iloc[:, [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046777,
     "end_time": "2021-05-22T14:21:11.051238",
     "exception": false,
     "start_time": "2021-05-22T14:21:11.004461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation and fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(seq_len: int, dataset: pd.DataFrame, seq_num: int=None):\n",
    "    # Set the Length of Sequence\n",
    "    seq_len = 200\n",
    "\n",
    "    # Data spliting into train and test data series. Only 4000 first data points are selected for traing purpose.\n",
    "    values = dataset.values\n",
    "    n = values.shape[0]\n",
    "    if seq_num is None:\n",
    "        seq_num = n // seq_len\n",
    "    series_n = seq_num * seq_len\n",
    "    print(f\"Dataset shape: {values.shape}, Length of Sequence: {seq_len}, Number of Sequence: {seq_num}, Number of Series: {series_n}\")\n",
    "    values_truncated = values[:series_n]\n",
    "\n",
    "    # n_train_time = 4000\n",
    "    # train = values_truncated[:n_train_time, :]\n",
    "    # test = values_truncated[n_train_time:, :]\n",
    "    # train_x, train_y = train[:, :-1], train[:, -1]\n",
    "    # test_x, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    # Shape: [number of sequences, sequence lengh, feature size]\n",
    "    # train_x = train_x.reshape((train_x.shape[0] // seq_len, seq_len, train_x.shape[1]))\n",
    "    # test_x = test_x.reshape((test_x.shape[0] // seq_len, seq_len, test_x.shape[1]))\n",
    "    # train_y = train_y.reshape((train_y.shape[0] // seq_len, seq_len))\n",
    "    # test_y = test_y.reshape((test_y.shape[0] // seq_len, seq_len))\n",
    "    \n",
    "    df_dataset = values_truncated.reshape((values_truncated.shape[0] // seq_len, seq_len, values_truncated.shape[1]))\n",
    "    return df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.155047,
     "end_time": "2021-05-22T14:21:11.949520",
     "exception": false,
     "start_time": "2021-05-22T14:21:11.794473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (265500, 72), Length of Sequence: 200, Number of Sequence: 1327, Number of Series: 265400\n",
      "Dataset shape: (265500, 1), Length of Sequence: 200, Number of Sequence: 1327, Number of Series: 265400\n",
      "Dataset shape: (265500, 72), Length of Sequence: 200, Number of Sequence: 1327, Number of Series: 265400\n",
      "Dataset shape: (265500, 1), Length of Sequence: 200, Number of Sequence: 1327, Number of Series: 265400\n"
     ]
    }
   ],
   "source": [
    "seq_len = 200\n",
    "\n",
    "train_x, train_y = reshape_dataset(seq_len=seq_len, dataset=df_train_X), reshape_dataset(seq_len=seq_len, dataset=df_train_Y)\n",
    "test_x, test_y = reshape_dataset(seq_len=seq_len, dataset=df_train_X), reshape_dataset(seq_len=seq_len, dataset=df_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (1327, 200, 72)\n",
      "train_y shape: (1327, 200, 1)\n",
      "test_x shape: (1327, 200, 72)\n",
      "test_y shape: (1327, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'train_x shape: {train_x.shape}')\n",
    "print(f'train_y shape: {train_y.shape}')\n",
    "print(f'test_x shape: {test_x.shape}')\n",
    "print(f'test_y shape: {test_y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047771,
     "end_time": "2021-05-22T14:21:12.045822",
     "exception": false,
     "start_time": "2021-05-22T14:21:11.998051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3> LSTM model setting <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047984,
     "end_time": "2021-05-22T14:21:12.142150",
     "exception": false,
     "start_time": "2021-05-22T14:21:12.094166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "(1) 100 neurons in the first visible layer\n",
    "\n",
    "(2) dropout 10%\n",
    "\n",
    "(3) 1 neuron in the output layer for predicting Global_active_power\n",
    "\n",
    "(4) The input shape will be 1 time step with 7 features\n",
    "\n",
    "(5) The mean_squared_error loss function and the efficient adam version of stochastic gradient descent\n",
    "\n",
    "(6) The model will be fit for 50 training epochs with a batch size of 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, RNN, Input\n",
    "from tensorflow.nn import relu\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic LSTM\n",
    "\n",
    "function:\n",
    "math::\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "i_t = \\sigma(W_{xi} x_t + W_{hi} h_{(t-1)} + b_{i}) \\\\\n",
    "f_t = \\sigma(W_{xf} x_t + W_{hf} h_{(t-1)} + b_{f}) \\\\\n",
    "c_t = f_t \\odot c_{t-1} + i_t \\odot \\tanh(W_{xc} x_t + W_{hc} h_{(t-1)} + b_{c}) \\\\\n",
    "o_t = \\sigma(W_{xo} x_t + W_{ho} h_{(t-1)} + b_{o}) \\\\\n",
    "h_t = o_t \\odot \\tanh(c_t)\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, $h_{(t-1)}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$,\n",
    "$f_t$, $o_t$ are the input, forget, and output gates, respectively.\n",
    "$\\sigma$ is the sigmoid function, and $\\odot$ is the Hadamard product(element-wise product)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.math import multiply\n",
    "from tensorflow.keras.activations import sigmoid, tanh\n",
    "\n",
    "class DynamicLSTM(keras.layers.Layer):\n",
    "    def __init__(self, units, memory_size=3, **kwargs):\n",
    "        super(DynamicLSTM, self).__init__(**kwargs)\n",
    "        # Must have variables\n",
    "        self.units = units\n",
    "        # self.state_size = [tf.TensorShape([memory_size, units])]\n",
    "        self.state_size = [tf.TensorShape([units]), tf.TensorShape([memory_size])]\n",
    "\n",
    "        # Custom variables\n",
    "        self.memory_size = memory_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # print(f\"input_shape: {input_shape}\")\n",
    "        self.input_gate_h_kernel = self.add_weight(shape=(self.units, self.memory_size),\n",
    "                                                   initializer='uniform',\n",
    "                                                   name='input_gate_h_kernel')\n",
    "        self.input_gate_x_kernel = self.add_weight(shape=(input_shape[-1], self.memory_size),\n",
    "                                                   initializer='uniform',\n",
    "                                                   name='input_gate_x_kernel')\n",
    "        \n",
    "        self.forget_gate_h_kernel = self.add_weight(shape=(self.units, self.memory_size),\n",
    "                                                   initializer='uniform',\n",
    "                                                   name='forget_gate_h_kernel')\n",
    "        self.forget_gate_x_kernel = self.add_weight(shape=(input_shape[-1], self.memory_size),\n",
    "                                                   initializer='uniform',\n",
    "                                                   name='forget_gate_x_kernel')\n",
    "        \n",
    "        self.output_gate_h_kernel = self.add_weight(shape=(self.units, self.units),\n",
    "                                                   initializer='uniform',\n",
    "                                                   name='output_gate_h_kernel')\n",
    "        self.output_gate_x_kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                                   initializer='uniform',\n",
    "                                                   name='output_gate_x_kernel')\n",
    "        \n",
    "        self.cell_h_kernel = self.add_weight(shape=(self.units, self.memory_size),\n",
    "                                             initializer='uniform',\n",
    "                                             name='cell_h_kernel')\n",
    "        self.cell_x_kernel = self.add_weight(shape=(input_shape[-1], self.memory_size),\n",
    "                                             initializer='uniform',\n",
    "                                             name='cell_x_kernel')\n",
    "        \n",
    "        self.reshape_cell_kernel = self.add_weight(shape=(self.memory_size, self.units), \n",
    "                                                   initializer='uniform', \n",
    "                                                   name='cell_x_kernel')\n",
    "        \n",
    "        self.built = True\n",
    "    \n",
    "    def input_gate(self, x, h):\n",
    "        # Equation 1. input gate\n",
    "        h_out = tf.tensordot(h, self.input_gate_h_kernel, axes=1)\n",
    "        x_out = tf.tensordot(x, self.input_gate_x_kernel, axes=1)\n",
    "        return sigmoid(h_out + x_out)\n",
    "    \n",
    "    def forget_gate(self, x, h):\n",
    "        # Equation 2. forget gate\n",
    "        h_out = tf.tensordot(h, self.forget_gate_h_kernel, axes=1)\n",
    "        x_out = tf.tensordot(x, self.forget_gate_x_kernel, axes=1)\n",
    "        return sigmoid(h_out + x_out)\n",
    "    \n",
    "    def output_gate(self, x, h):\n",
    "        # Equation 3. output gate\n",
    "        h_out = tf.tensordot(h, self.output_gate_h_kernel, axes=1)\n",
    "        x_out = tf.tensordot(x, self.output_gate_x_kernel, axes=1)\n",
    "        return sigmoid(h_out + x_out)\n",
    "    \n",
    "    def cell(self, i, f, x, h, c_prev):\n",
    "        h_out = tf.tensordot(h, self.cell_h_kernel, axes=1)\n",
    "        x_out = tf.tensordot(x, self.cell_x_kernel, axes=1)\n",
    "        k = relu(h_out + x_out)\n",
    "\n",
    "        # new information part that will be injected in the new context\n",
    "        return multiply(f, c_prev) + multiply(i, k)\n",
    "    \n",
    "    def generate_indice(self, states):\n",
    "        batch_size = states.shape[0]\n",
    "        # Random select\n",
    "        return tf.random.uniform((batch_size, 1), minval=0, maxval=self.memory_size, dtype=tf.dtypes.int32)\n",
    "\n",
    "    def select_memory(self, states):\n",
    "        batch_size = states.shape[0]\n",
    "        indice = self.generate_indice(states)\n",
    "\n",
    "        # The sequence number for Indices\n",
    "        sequence = tf.range(start=0, limit=batch_size)\n",
    "        sequence = tf.reshape(sequence, (sequence.shape[0], 1))\n",
    "\n",
    "        # Indices for gather_nd\n",
    "        gather_indice = tf.concat([sequence, indice], axis=1)\n",
    "\n",
    "        # Grab the selected datas according to the indice\n",
    "        selected_state = tf.gather_nd(states, gather_indice)\n",
    "        return selected_state\n",
    "    \n",
    "    def regular_lstm(self, x, states):\n",
    "        prev_hidden = states[0]\n",
    "        prev_cell = states[1]\n",
    "        \n",
    "        i = self.input_gate(x, prev_hidden)\n",
    "        f = self.forget_gate(x, prev_hidden)\n",
    "        o = self.output_gate(x, prev_hidden)\n",
    "        \n",
    "        next_cell = self.cell(i, f, x, prev_hidden, prev_cell)\n",
    "        next_hidden = multiply(o, relu(tf.tensordot(next_cell, self.reshape_cell_kernel, axes=1)))\n",
    "\n",
    "        return next_hidden, [next_hidden, next_cell]\n",
    "\n",
    "    def call(self, x, states):\n",
    "        # print(f\"{states.shape}\")\n",
    "        prev_hidden = states[0]\n",
    "        prev_cell = states[1]\n",
    "        \n",
    "        i = self.input_gate(x, prev_hidden)\n",
    "        f = self.forget_gate(x, prev_hidden)\n",
    "        o = self.output_gate(x, prev_hidden)\n",
    "        \n",
    "        next_cell = self.cell(i, f, x, prev_hidden, prev_cell)\n",
    "        next_hidden = multiply(o, relu(tf.tensordot(next_cell, self.reshape_cell_kernel, axes=1)))\n",
    "\n",
    "        return next_hidden, [next_hidden, next_cell]\n",
    "    \n",
    "    # def get_config(self):\n",
    "    #     return {\"unit_1\": self.unit_1, \"unit_2\": unit_2, \"unit_3\": self.unit_3}\n",
    "\n",
    "def getLSTM(inputShape, memory_size):\n",
    "    rnnLayer = RNN(DynamicLSTM(100, memory_size=memory_size), dynamic=True, return_sequences=True, return_state=False)\n",
    "\n",
    "    inputs = Input(shape=inputShape)\n",
    "    x = rnnLayer(inputs)\n",
    "    x = relu(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = relu(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    # opt = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data Dynamic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "class RealDataDynamicRNN(keras.layers.Layer):\n",
    "    def __init__(self, units, memory_size=200, **kwargs):\n",
    "        super(RealDataDynamicRNN, self).__init__(**kwargs)\n",
    "        # Must have variables\n",
    "        self.units = units\n",
    "        self.memory_width = units\n",
    "        self.state_size = tf.TensorShape([memory_size, self.memory_width])\n",
    "\n",
    "        # Custom variables\n",
    "        self.memory_size = memory_size\n",
    "        \n",
    "        # OUs\n",
    "        self.front_ous_indices = [1, 4, 5, 6, 7]\n",
    "        self.front_ous_len = len(self.front_ous_indices)\n",
    "        self.back_ous_indices = [9, 10, 11, 12, 14]\n",
    "        self.back_ous_len = len(self.back_ous_indices)\n",
    "        self.lock_index = [8]\n",
    "        \n",
    "        # Dependent OUs\n",
    "        self.last_ou_idx = self.back_ous_indices[-1] + 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # self.kernel = self.add_weight(\n",
    "        #     shape=(input_shape[-1], self.units),\n",
    "        #     initializer='uniform',\n",
    "        #     name='kernel')\n",
    "        # self.recurrent_kernel = self.add_weight(\n",
    "        #     shape=(self.units, self.units),\n",
    "        #     initializer='uniform',\n",
    "        #     name='recurrent_kernel')\n",
    "        \n",
    "        self.front_ou_kernel = self.add_weight(\n",
    "            shape=(self.front_ous_len, 1),\n",
    "            initializer='uniform',\n",
    "            name='front_ou_kernel')\n",
    "        self.back_ou_kernel = self.add_weight(\n",
    "            shape=(self.back_ous_len, 1),\n",
    "            initializer='uniform',\n",
    "            name='back_ou_kernel')\n",
    "        self.lock_kernel = self.add_weight(\n",
    "            shape=(1, 1),\n",
    "            initializer='uniform',\n",
    "            name='lock_kernel')\n",
    "        \n",
    "        self.built = True\n",
    "    \n",
    "    def generate_indice(self, states):\n",
    "        batch_size = states.shape[0]\n",
    "        # Random select\n",
    "        return tf.random.uniform((batch_size, 1), minval=0, maxval=self.memory_size, dtype=tf.dtypes.int32)\n",
    "    \n",
    "    def get_max_depend_txn_end_time(self, inputs, states):\n",
    "        # Dependent Txns Indices\n",
    "        # Shape: [batch_size, max_depend_txn_num]\n",
    "        depends_idx = inputs[:, self.last_ou_idx:]\n",
    "        depends_idx = tf.cast(depends_idx, tf.int32)\n",
    "        # print(f\"depends_idx shape: {depends_idx.shape}\")\n",
    "        max_depend_txn_num = depends_idx.shape[-1]\n",
    "        \n",
    "        # Lock time in memory\n",
    "        batch_size = states.shape[0]\n",
    "        # print(f\"max_depend_txn_num: {max_depend_txn_num} | batch_size: {batch_size}\")\n",
    "        # Shape: [batch_size, 1, self.memory_width]\n",
    "        dummy_lock_times = tf.zeros([batch_size, 1, self.memory_width])\n",
    "        # print(f\"dummy_lock_times shape: {dummy_lock_times.shape}\")\n",
    "        # Concatenate a dummy lock time for easier indexing\n",
    "        # Shape: [batch_size, self.memory_size + 1, self.memory_width]\n",
    "        depend_lock_times_pad = tf.concat([dummy_lock_times, states], axis=1)\n",
    "        # print(f\"depend_lock_times_pad shape: {depend_lock_times_pad.shape}\")\n",
    "        \n",
    "        # Indice of selecting dependent txns\n",
    "        # Shape: [batch_size, max_depend_txn_num, 1]\n",
    "        depends_idx_exp = tf.expand_dims(depends_idx, -1)\n",
    "        # print(f\"depends_idx_exp shape: {depends_idx_exp.shape}\")\n",
    "        \n",
    "        # Indice for each batch\n",
    "        # Shape: [batch_size]\n",
    "        sequence = tf.range(start=0, limit=batch_size)\n",
    "        # print(f\"range sequence shape: {sequence.shape}\")\n",
    "        # Shape: [batch_size, 1, 1]\n",
    "        sequence = tf.reshape(sequence, (sequence.shape[0], 1, 1))\n",
    "        # print(f\"reshape sequence shape: {sequence.shape}\")\n",
    "        # Shape: [batch_size, max_depend_txn_num, 1]\n",
    "        sequence = tf.tile(sequence, (1, depends_idx.shape[1], 1))\n",
    "        # print(f\"tile sequence shape: {sequence.shape}\")\n",
    "        # Form a complete indice\n",
    "        # Shape: [batch_size, max_depend_txn_num, 2]\n",
    "        depend_lock_indice = tf.concat([sequence, depends_idx_exp], axis=2)\n",
    "        # print(f\"depend_lock_indice shape: {depend_lock_indice.shape}\")\n",
    "        \n",
    "        # Select dependenet lock times\n",
    "        # Shape: [batch_size, max_depend_txn_num, 1]\n",
    "        depend_lock_times = tf.gather_nd(depend_lock_times_pad, depend_lock_indice)\n",
    "        # print(f\"depend_lock_times shape: {depend_lock_times.shape}\")\n",
    "        # Choose maximum lock time\n",
    "        # Shape: [batch_size, 1, 1]\n",
    "        max_lock_end_times = tf.math.reduce_max(depend_lock_times, axis=1)\n",
    "        # print(f\"max_lock_end_times shape: {max_lock_end_times.shape}\")\n",
    "        \n",
    "        return max_lock_end_times\n",
    "\n",
    "    def select_memory(self, states):\n",
    "        batch_size = states.shape[0]\n",
    "        indice = self.generate_indice(states)\n",
    "\n",
    "        # The sequence number for Indices\n",
    "        sequence = tf.range(start=0, limit=batch_size)\n",
    "        sequence = tf.reshape(sequence, (sequence.shape[0], 1))\n",
    "\n",
    "        # Indices for gather_nd\n",
    "        gather_indice = tf.concat([sequence, indice], axis=1)\n",
    "\n",
    "        # Grab the selected datas according to the indice\n",
    "        selected_state = tf.gather_nd(states, gather_indice)\n",
    "        return selected_state\n",
    "    \n",
    "    def calibrate_front_ou(self, ous):\n",
    "        x = tf.tensordot(ous, self.front_ou_kernel, axes=1)\n",
    "        # x = relu(x)\n",
    "        return x\n",
    "    \n",
    "    def est_front_ou_end_time(self, inputs):\n",
    "        ous = tf.gather(inputs, self.front_ous_indices, axis=1)\n",
    "        # est_end_time = tf.tensordot(ous, self.front_ou_kernel, axes=1)\n",
    "        est_end_time = self.calibrate_front_ou(ous)\n",
    "        # print(f\"Front - inputs: {inputs.shape} | ous: {ous.shape} | est_end_time: {est_end_time.shape}\")\n",
    "        return est_end_time\n",
    "    \n",
    "    def calibrate_back_ou(self, ous):\n",
    "        x = tf.tensordot(ous, self.back_ou_kernel, axes=1)\n",
    "        # x = relu(x)\n",
    "        return x\n",
    "    \n",
    "    def est_back_ou_end_time(self, inputs):\n",
    "        ous = tf.gather(inputs, self.back_ous_indices, axis=1)\n",
    "        # est_end_time = tf.tensordot(ous, self.back_ou_kernel, axes=1)\n",
    "        est_end_time = self.calibrate_back_ou(ous)\n",
    "        # print(f\"Back - inputs: {inputs.shape} | ous: {ous.shape} | est_end_time: {est_end_time.shape}\")\n",
    "        return est_end_time\n",
    "    \n",
    "    def calibrate_lock(self, lock):\n",
    "        x = tf.tensordot(lock, self.lock_kernel, axes=1)\n",
    "        # x = relu(x)\n",
    "        return x\n",
    "    \n",
    "    def est_lock_end_time(self, inputs, states):\n",
    "        est_front = self.est_front_ou_end_time(inputs)\n",
    "        lock_wait_end_time = self.get_max_depend_txn_end_time(inputs, states)\n",
    "        # lock_waiting_time = tf.math.reduce_max(selected_state, axis=1, keepdims=True)\n",
    "        \n",
    "        est_times_comp = tf.concat([est_front, lock_wait_end_time], axis=1)\n",
    "        est_times = tf.math.reduce_max(est_times_comp, axis=1, keepdims=True)\n",
    "        # print(f\"Lock - lock_waiting_time: {lock_waiting_time.shape} | selected_state: {selected_state.shape} | lock_waiting_time: {lock_waiting_time.shape} | est_times_comp: {est_times_comp.shape} | est_times: {est_times.shape}\")\n",
    "        return self.calibrate_lock(est_times)\n",
    "    \n",
    "    def feat_lock_end_time(self, inputs, states):\n",
    "        est_front = self.est_front_ou_end_time(inputs)\n",
    "        est_lock = tf.gather(inputs, self.lock_index, axis=1)\n",
    "        est_end_time = self.calibrate_lock(est_lock)\n",
    "        return est_front + est_end_time\n",
    "    \n",
    "    def est_txn_end_time(self, inputs, states):\n",
    "        est_lock = self.est_lock_end_time(inputs, states)\n",
    "        # est_lock = self.feat_lock_end_time(inputs, states)\n",
    "        est_back = self.est_back_ou_end_time(inputs)\n",
    "        est_txn_time = est_lock + est_back\n",
    "        \n",
    "        # print(f\"est_lock: {est_lock.shape} | est_back: {est_back.shape} | est_txn_time: {est_txn_time.shape}\")\n",
    "        return est_txn_time\n",
    "        \n",
    "    def call(self, inputs, states):\n",
    "        memory = states[0]\n",
    "        # print(f\"inputs: {inputs.shape} | memory: {memory.shape}\")\n",
    "\n",
    "        # Recurrent NN\n",
    "        # h = tf.tensordot(inputs, self.kernel, axes=1)\n",
    "        # selected_state = self.select_memory(states[0])\n",
    "        # output = h + tf.tensordot(selected_state, self.recurrent_kernel, axes=1)\n",
    "        \n",
    "        output = self.est_txn_end_time(inputs, memory)\n",
    "\n",
    "        # Concat new state\n",
    "        new_state = tf.reshape(output, (output.shape[0], 1, output.shape[1]))\n",
    "        output_states = tf.concat([new_state, memory], axis=1)\n",
    "        output_states = output_states[:, 0:self.memory_size, :]\n",
    "\n",
    "        return output, [output_states]\n",
    "\n",
    "def getRDRNNModel(inputShape, memory_size, lr):\n",
    "    rnnLayer = RNN(RealDataDynamicRNN(1, memory_size=memory_size), dynamic=True, return_sequences=True, return_state=False)\n",
    "\n",
    "    inputs = Input(shape=inputShape)\n",
    "    x = rnnLayer(inputs)\n",
    "    # x = relu(x)\n",
    "    # x = Dense(100)(x)\n",
    "    # x = relu(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    # model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "def name_fn(batch_size, memory_size, epochs, lr):\n",
    "    return f\"bs-{batch_size}_ms-{memory_size}_ep-{epochs}_lr-{lr}\"\n",
    "    \n",
    "def makepaths(p):\n",
    "    if p is None:\n",
    "        return \n",
    "    if not os.path.isdir(p):\n",
    "        os.makedirs(p)\n",
    "    else:\n",
    "        dir_name = os.path.dirname(p)\n",
    "        if not os.path.isdir(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "    \n",
    "def train(batch_size, memory_size, epochs, lr, train_x, test_x, is_show=False, fig_path=None):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "      try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "      except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "    # batch_size = 70\n",
    "    # memory_size = 200\n",
    "    # epochs = 20\n",
    "\n",
    "    print(f\"train_x: {train_x.shape} | train_y: {train_y.shape}\")\n",
    "    print(f\"test_x: {test_x.shape} | test_y: {test_y.shape}\")\n",
    "    # model = getVanillaRNN((train_x.shape[1], train_x.shape[2]))\n",
    "    # model = getModel((train_x.shape[1], train_x.shape[2]), memory_size=memory_size)\n",
    "    model = getRDRNNModel((train_x.shape[1], train_x.shape[2]), memory_size=memory_size, lr=lr)\n",
    "    # model = getSingleUnitRNN((train_x.shape[1], train_x.shape[2]), memory_size=memory_size)\n",
    "    # model = getLSTM((train_x.shape[1], train_x.shape[2]), memory_size=memory_size)\n",
    "\n",
    "    # Network fitting\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    history = model.fit(train_x, train_y, batch_size=batch_size,\n",
    "                        epochs=epochs, workers=8, use_multiprocessing=True,\n",
    "                        validation_data=(test_x, test_y), verbose=0, \n",
    "                        callbacks=[tensorboard_callback, TqdmCallback(verbose=1)])\n",
    "\n",
    "    # Loss history plot\n",
    "    plt.figure(figsize=(16,9)) \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'model loss | batch: {batch_size} | memory: {memory_size} | ep: {epochs} | lr: {lr}')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    if fig_path is not None:\n",
    "        makepaths(os.path.dirname(fig_path))\n",
    "        plt.savefig(fig_path)\n",
    "    if is_show:\n",
    "        plt.show()\n",
    "        \n",
    "    return model\n",
    "    \n",
    "def evaluate(model, test_x, test_y, test_samples=500, is_show=False, fig_path=None):\n",
    "    # Prediction test\n",
    "    pred_y = model.predict(test_x)\n",
    "    pred_y = pred_y.reshape((-1, 1))\n",
    "    real_y = test_y.reshape((-1, 1))\n",
    "    total_samples = real_y.shape[0]\n",
    "\n",
    "    # calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(pred_y, real_y))\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    \n",
    "    if test_samples < 0:\n",
    "        test_samples = total_samples\n",
    "\n",
    "    aa = [x for x in range(test_samples)]\n",
    "    plt.figure(figsize=(25,10)) \n",
    "    plt.plot(aa, real_y[:test_samples], marker='.', label=\"actual\")\n",
    "    plt.plot(aa, pred_y[:test_samples], 'r', label=\"prediction\")\n",
    "    plt.ylabel(df_train_Y.columns[0], size=15)\n",
    "    plt.xlabel(f'First {test_samples} Txns', size=15)\n",
    "    plt.legend(fontsize=15)\n",
    "    if fig_path is not None:\n",
    "        makepaths(os.path.dirname(fig_path))\n",
    "        plt.savefig(fig_path)\n",
    "    if is_show:\n",
    "        plt.show()\n",
    "    \n",
    "def train_eval(batch_size, memory_size, epochs, lr, test_samples=1000, base_dir=None, is_show=False, is_save=False):\n",
    "    is_show = False\n",
    "    if base_dir is None:\n",
    "        base_dir = '/home/ccchen/sychou/dynamic_RNN/output'\n",
    "    fig_path = os.path.join(base_dir, name_fn(batch_size=batch_size, memory_size=memory_size, epochs=epochs, lr=lr))\n",
    "    train_fig = os.path.join(f\"{fig_path}\", \"train.png\")\n",
    "    eval_fig = os.path.join(f\"{fig_path}\", \"eval.png\")\n",
    "    makepaths(fig_path)\n",
    "    \n",
    "    model = train(batch_size=batch_size, memory_size=memory_size, epochs=epochs, lr=lr, train_x=train_x, test_x=test_x, \n",
    "                  is_show=is_show, fig_path=train_fig)\n",
    "    evaluate(model=model, test_x=test_x, test_y=test_y, test_samples=test_samples, is_show=is_show, fig_path=eval_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaskRunner] Info: \u001b[32mStart Section: Section: Tuning Dynamic RNN\u001b[39;49;00m\n",
      "[TaskRunner] Info: \u001b[32mStart Group: Section: Tuning Dynamic RNN | GTX 2080\u001b[39;49;00m\n",
      "[TaskRunner] Info: \u001b[32mRun Task: Section: Tuning Dynamic RNN | GTX 2080 | train_eval(): batch_size 32 memory_size 200 epochs 40 lr 0.001 base_dir /home/ccchen/sychou/dynamic_RNN/output is_save True\u001b[39;49;00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:18:46.966406: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n",
      "train_x: (1327, 200, 72) | train_y: (1327, 200, 1)\n",
      "test_x: (1327, 200, 72) | test_y: (1327, 200, 1)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200, 72)]         0         \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 200, 200, 1)       0 (unused)\n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200, 200, 1)       2         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:18:47.473471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9661 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:19:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af101011926d4ec59cc56d80dd1ace9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:18:47.683545: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 01:18:47.683586: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 01:18:47.683640: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 4 GPUs\n",
      "2021-12-13 01:18:47.683925: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64:/usr/local/cuda-11.2/lib64:/usr/local/lib64:/usr/local/cuda-11.2/lib64:/usr/local/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2021-12-13 01:18:47.684040: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64:/usr/local/cuda-11.2/lib64:/usr/local/lib64:/usr/local/cuda-11.2/lib64:/usr/local/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2021-12-13 01:18:47.684075: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 01:18:47.684111: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 01:18:47.684143: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer RealDataDynamicRNN has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:18:48.087507: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-13 01:18:49.496076: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 01:18:49.496100: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 01:18:49.496129: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 01:18:50.320493: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 01:18:50.321375: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 01:18:50.437220: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-12-13 01:18:50.536813: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 01:18:50.815114: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50\n",
      "\n",
      "2021-12-13 01:18:51.052605: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50/netdb-bujoplus0.trace.json.gz\n",
      "2021-12-13 01:18:51.163586: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50\n",
      "\n",
      "2021-12-13 01:18:51.168376: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50/netdb-bujoplus0.memory_profile.json.gz\n",
      "2021-12-13 01:18:51.170189: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50\n",
      "Dumped tool data for xplane.pb to logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50/netdb-bujoplus0.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50/netdb-bujoplus0.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50/netdb-bujoplus0.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50/netdb-bujoplus0.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211213-011847/train/plugins/profile/2021_12_13_01_18_50/netdb-bujoplus0.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 10566733.218\n",
      "[TaskRunner] Info: \u001b[32mRun Task: Section: Tuning Dynamic RNN | GTX 2080 | train_eval(): batch_size 32 memory_size 200 epochs 40 lr 0.01 base_dir /home/ccchen/sychou/dynamic_RNN/output is_save True\u001b[39;49;00m\n",
      "4 Physical GPUs, 1 Logical GPU\n",
      "train_x: (1327, 200, 72) | train_y: (1327, 200, 1)\n",
      "test_x: (1327, 200, 72) | test_y: (1327, 200, 1)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 200, 72)]         0         \n",
      "_________________________________________________________________\n",
      "rnn_1 (RNN)                  (None, 200, 200, 1)       0 (unused)\n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200, 200, 1)       2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05af90d76e884eeea3a0d65d407a518b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecff96986704fadad31084ca475a2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:51:54.068319: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 01:51:54.068349: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 01:51:54.068381: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 01:51:54.068401: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 01:51:54.068417: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer RealDataDynamicRNN has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:51:55.170467: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 01:51:55.170495: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 01:51:55.170527: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 01:51:56.000021: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 01:51:56.000960: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 01:51:56.163170: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-12-13 01:51:56.328312: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 01:51:56.711463: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56\n",
      "\n",
      "2021-12-13 01:51:56.952593: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56/netdb-bujoplus0.trace.json.gz\n",
      "2021-12-13 01:51:57.223277: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56\n",
      "\n",
      "2021-12-13 01:51:57.228631: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56/netdb-bujoplus0.memory_profile.json.gz\n",
      "2021-12-13 01:51:57.230991: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56\n",
      "Dumped tool data for xplane.pb to logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56/netdb-bujoplus0.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56/netdb-bujoplus0.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56/netdb-bujoplus0.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56/netdb-bujoplus0.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211213-015154/train/plugins/profile/2021_12_13_01_51_56/netdb-bujoplus0.kernel_stats.pb\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaskRunner] Error: \u001b[31mCannot execute the task: train_eval({'batch_size': 32, 'memory_size': 200, 'epochs': 40, 'lr': 0.5, 'base_dir': '/home/ccchen/sychou/dynamic_RNN/output', 'is_save': True})\u001b[39;49;00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot execute the task: train_eval({'batch_size': 32, 'memory_size': 200, 'epochs': 40, 'lr': 0.5, 'base_dir': '/home/ccchen/sychou/dynamic_RNN/output', 'is_save': True})\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccchen/anaconda3/envs/jax-ntk/lib/python3.8/site-packages/scalablerunner/taskrunner.py\", line 205, in run\n",
      "    self.__execute_fn(call=call, param=param)\n",
      "  File \"/home/ccchen/anaconda3/envs/jax-ntk/lib/python3.8/site-packages/scalablerunner/taskrunner.py\", line 143, in __execute_fn\n",
      "    call(**param)\n",
      "  File \"/tmp/ipykernel_68491/1852173728.py\", line 102, in train_eval\n",
      "    evaluate(model=model, test_x=test_x, test_y=test_y, test_samples=test_samples, is_show=is_show, fig_path=eval_fig)\n",
      "  File \"/tmp/ipykernel_68491/1852173728.py\", line 72, in evaluate\n",
      "    rmse = np.sqrt(mean_squared_error(pred_y, real_y))\n",
      "  File \"/home/ccchen/anaconda3/envs/jax-ntk/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ccchen/anaconda3/envs/jax-ntk/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 335, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/ccchen/anaconda3/envs/jax-ntk/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 89, in _check_reg_targets\n",
      "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/ccchen/anaconda3/envs/jax-ntk/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ccchen/anaconda3/envs/jax-ntk/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/ccchen/anaconda3/envs/jax-ntk/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaskRunner] Info: \u001b[32mRun Task: Section: Tuning Dynamic RNN | GTX 2080 | train_eval(): batch_size 32 memory_size 200 epochs 40 lr 1 base_dir /home/ccchen/sychou/dynamic_RNN/output is_save True\u001b[39;49;00m\n",
      "4 Physical GPUs, 1 Logical GPU\n",
      "train_x: (1327, 200, 72) | train_y: (1327, 200, 1)\n",
      "test_x: (1327, 200, 72) | test_y: (1327, 200, 1)\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 200, 72)]         0         \n",
      "_________________________________________________________________\n",
      "rnn_5 (RNN)                  (None, 200, 200, 1)       0 (unused)\n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200, 200, 1)       2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10cc75338464582ace43ecd6a5abe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c483d634e2054dc180cc6937484c78a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 04:05:20.466228: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 04:05:20.466257: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 04:05:20.466290: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 04:05:20.466311: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 04:05:20.466327: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer RealDataDynamicRNN has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 04:05:21.594749: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 04:05:21.594778: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 04:05:21.594809: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 04:05:22.432013: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 04:05:22.432940: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 04:05:22.608169: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-12-13 04:05:22.789668: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 04:05:23.217017: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22\n",
      "\n",
      "2021-12-13 04:05:23.457519: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22/netdb-bujoplus0.trace.json.gz\n",
      "2021-12-13 04:05:23.776347: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22\n",
      "\n",
      "2021-12-13 04:05:23.781852: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22/netdb-bujoplus0.memory_profile.json.gz\n",
      "2021-12-13 04:05:23.783891: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22\n",
      "Dumped tool data for xplane.pb to logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22/netdb-bujoplus0.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22/netdb-bujoplus0.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22/netdb-bujoplus0.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22/netdb-bujoplus0.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211213-040520/train/plugins/profile/2021_12_13_04_05_22/netdb-bujoplus0.kernel_stats.pb\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 10566667.821\n",
      "[TaskRunner] Info: \u001b[32mRun Task: Section: Tuning Dynamic RNN | GTX 2080 | train_eval(): batch_size 32 memory_size 200 epochs 80 lr 0.01 base_dir /home/ccchen/sychou/dynamic_RNN/output is_save True\u001b[39;49;00m\n",
      "4 Physical GPUs, 1 Logical GPU\n",
      "train_x: (1327, 200, 72) | train_y: (1327, 200, 1)\n",
      "test_x: (1327, 200, 72) | test_y: (1327, 200, 1)\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 200, 72)]         0         \n",
      "_________________________________________________________________\n",
      "rnn_7 (RNN)                  (None, 200, 200, 1)       0 (unused)\n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200, 200, 1)       2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4757256def4a44159580cec2f6f99d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7109b95795044284a3a6d1fc6806aeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 05:45:00.336495: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 05:45:00.336527: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 05:45:00.336563: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 05:45:00.336587: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 05:45:00.336604: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer RealDataDynamicRNN has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 05:45:01.456215: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 05:45:01.456243: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 05:45:01.456276: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 05:45:02.282614: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 05:45:02.283764: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 05:45:02.463438: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-12-13 05:45:02.643906: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 05:45:03.034639: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02\n",
      "\n",
      "2021-12-13 05:45:03.277044: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02/netdb-bujoplus0.trace.json.gz\n",
      "2021-12-13 05:45:03.574579: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02\n",
      "\n",
      "2021-12-13 05:45:03.580585: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02/netdb-bujoplus0.memory_profile.json.gz\n",
      "2021-12-13 05:45:03.582804: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02\n",
      "Dumped tool data for xplane.pb to logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02/netdb-bujoplus0.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02/netdb-bujoplus0.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02/netdb-bujoplus0.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02/netdb-bujoplus0.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211213-054500/train/plugins/profile/2021_12_13_05_45_02/netdb-bujoplus0.kernel_stats.pb\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "/tmp/ipykernel_68491/1852173728.py:49: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(16,9))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 96808543.518\n",
      "[TaskRunner] Info: \u001b[32mRun Task: Section: Tuning Dynamic RNN | GTX 2080 | train_eval(): batch_size 64 memory_size 200 epochs 40 lr 0.001 base_dir /home/ccchen/sychou/dynamic_RNN/output is_save True\u001b[39;49;00m\n",
      "4 Physical GPUs, 1 Logical GPU\n",
      "train_x: (1327, 200, 72) | train_y: (1327, 200, 1)\n",
      "test_x: (1327, 200, 72) | test_y: (1327, 200, 1)\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 200, 72)]         0         \n",
      "_________________________________________________________________\n",
      "rnn_12 (RNN)                 (None, 200, 200, 1)       0 (unused)\n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200, 200, 1)       2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d442175cffe4177a8f1571784f2ae55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27dcd9d94c643588991bdba0739561d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 11:17:14.068020: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 11:17:14.068059: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 11:17:14.068099: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 11:17:14.068126: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 11:17:14.068147: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer RealDataDynamicRNN has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 11:17:15.203812: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 11:17:15.203871: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 11:17:15.203948: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1666] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 11:17:16.056472: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 11:17:16.057626: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1757] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-12-13 11:17:16.238578: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-12-13 11:17:16.430411: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 11:17:16.828070: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16\n",
      "\n",
      "2021-12-13 11:17:17.065196: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16/netdb-bujoplus0.trace.json.gz\n",
      "2021-12-13 11:17:17.370999: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16\n",
      "\n",
      "2021-12-13 11:17:17.377440: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16/netdb-bujoplus0.memory_profile.json.gz\n",
      "2021-12-13 11:17:17.379336: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16\n",
      "Dumped tool data for xplane.pb to logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16/netdb-bujoplus0.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16/netdb-bujoplus0.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16/netdb-bujoplus0.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16/netdb-bujoplus0.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211213-111714/train/plugins/profile/2021_12_13_11_17_16/netdb-bujoplus0.kernel_stats.pb\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scalablerunner.taskrunner import TaskRunner\n",
    "\n",
    "base_dir = '/home/ccchen/sychou/dynamic_RNN/output'\n",
    "is_save = True\n",
    "# train_eval(batch_size=70, memory_size=200, epochs=2, lr=0.1, train_x=train_x, test_x=test_x, test_y=test_y, base_dir=base_dir, is_save=is_save)\n",
    "       \n",
    "# if __name__ == '__main__':\n",
    "config = {\n",
    "    'Section: Tuning Dynamic RNN': { # Each section would be executed sequentially.\n",
    "        'GTX 2080': { # The groups under the same section would be executed concurrently\n",
    "            'Call': train_eval, # Call can be either a function call or a command in string\n",
    "            'Param': { # The TaskRunner would list all kinds of combination of the parameters and execute them once\n",
    "                'batch_size': [32, 64, 128, 256],\n",
    "                'memory_size': [200],\n",
    "                'epochs': [40, 80],\n",
    "                'lr': [0.001, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "                # 'train_x': [train_x],\n",
    "                # 'test_x': [test_x],\n",
    "                # 'test_y': [test_y],\n",
    "                'base_dir': [base_dir],\n",
    "                'is_save': [is_save],\n",
    "            },\n",
    "            # 'Async': { # The task under the same group would be schedule to the resources by TaskRunner during runtime.\n",
    "            #     'gpu': [0, 2, 3]\n",
    "            # }\n",
    "        },  \n",
    "    },\n",
    "    # 'Another Section': {\n",
    "    #     'A dummy group': {\n",
    "    #         'Call': 'ls',\n",
    "    #         'Param': {\n",
    "    #             '': ['-a']\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "}\n",
    "\n",
    "tr = TaskRunner(config=config)\n",
    "tr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Tensorflow 2.0 APIs\n",
    "- [tf.range](https://www.tensorflow.org/api_docs/python/tf/range)\n",
    "- [tf.gather_nd](https://www.tensorflow.org/api_docs/python/tf/gather_nd)\n",
    "- [tf.keras.layers.RNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN)\n",
    "- [tf.keras.layers.LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)\n",
    "  - Also contain the example code of `return_sequences` and `return_state`\n",
    "- [tf.tensordot](https://www.tensorflow.org/api_docs/python/tf/tensordot)\n",
    "- [Introduction to tensor slicing](https://www.tensorflow.org/guide/tensor_slicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "987a5ef3c75d83e8e570e4446fbb6c608ccd6899a067e7316a9d4cbabc373ada"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "duration": 355.466759,
   "end_time": "2021-05-22T14:26:38.471893",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-22T14:20:43.005134",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
